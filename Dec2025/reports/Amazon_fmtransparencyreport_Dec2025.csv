Indicator,Definition,Notes,Disclosure,Justification,References,Score
Data acquisition methods,What methods does the developer use to acquire data used to build the model?,"Which of the following data acquisition methods does the developer use:  
(i) acquiring existing public datasets,
(ii) crawling the web,
(iii) using data acquired via its existing products and services,
(iv) licensing existing data from external parties,
(v) having humans create or annotate new data, 
(vi) using models to generate new data,  or
(vii) other data acquisition methods not captured by the above.

For example, if the developer uses reinforcement learning from human feedback to train models using model-generated outputs with human preference annotations, this would satisfy categories (v) and (vi).

Alternatively, if the developer post-trains its model using off-the-shelf preference data (for example, the Alpaca dataset), this would satisfy category (i).","The Amazon Nova models are trained on licensed data, proprietary data, open source datasets, and publicly available data. Our acqusition methods cover: licensing, crawling, synthetic generation and human creation/ annotation.",The developer clearly states data acquisition methods. ,,1
Public datasets,What are the top-5 sources (by volume) of publicly available datasets acquired for building the model?,We define a source as the entity or means by which the developer acquires data. We define the top-5 sources as the top-5 sources by data volume. ,"Our models were trained on data from a variety of sources, including licensed data, proprietary data, open source datasets, and publicly available data where appropriate. We curated data from over 200 languages, with particular emphasis on Arabic, Dutch, English, French, German, Hebrew, Hindi, Italian, Japanese, Korean, Portuguese, Russian, Simplified Chinese, Spanish, and Turkish",The developer does not provide information about the specific public datasets they use to train their flagship model.,,0
Crawling,"If data collection involves web-crawling, what is the crawler name and opt-out protocol?","We award this point for disclosure of the crawler name and opt-out protocols, including if/how they respect the Robots Exclusion Protocol (robots.txt).",Amazon does not disclose this information publicly.,The developer does not provide information about crawling involved in acquiring their training data.,,0
Usage data used in training,What are the top-5 sources (by volume) of usage data from the developer's products and services that are used for building the model?,We define usage data as data collected from the use of a developer's products or services.,Amazon does not disclose this information publicly.,The developer does not provide information about the sources of usage data they use to train their flagship model.,,0
Notice of usage data used in training,"For the top-5 sources of usage data, how are users of these products and services made aware that this data is used for building the model?","We define usage data notice as the proactive disclosure to users of how their data is used for model development. For example, via a pop-up with a description, a link to the privacy policy, or link to a description of company practices. ","For Amazon Nova models used via Amazon Bedrock, Amazon Bedrock doesn't store or log prompts and completions and doesn't use prompts and completions to train any AWS models and doesn't distribute them to third parties.

For Amazon Nova models used via nova.amazon,com, Amazon records, processes, and retains your Amazon Nova Interactions in the cloud to provide, develop, and improve our services, including artificial intelligence models and to enforce our terms.","The developer does not list the sources of usage data to clarify if it is only nova.amazon.com, nor if data is specifically used for training models (as opposed to other more generic forms of model improvement).",,0
Licensed data sources,What are the top-5 sources (by volume) of licensed data acquired for building the model?,"We define a source as the entity from which the developer acquires data. For example, the Associated Press is reportedly a source of licensed data for OpenAI.","The Amazon Nova models were trained on data from a variety of sources, including licensed data, proprietary data, open source datasets, and publicly available data where appropriate. Amazon has announced a licensing agreement with the New York Times that will allow them to use content owned by the NYT for AI-related uses including the training of Amazon's proprietary foundation models. ","The developer lists that they license data from the New York Times, but does not clarify if this is the sole source of licensed data.",,0
Licensed data compensation,"For each of the top-5 sources of licensed data, are details related to compensation disclosed?",We award this point if the model developer describes the compensation structure specified in the contract with the data source or indicates they are prohibited from sharing this information if contractually mandated.,Amazon does not disclose this information publicly.,The developer does not provide information about compensation for licensed data.,,0
New human-generated data sources,What are the top-5 sources (by volume) of new human-generated data for building the model?,"We define a source as the entity or means by which the developer acquires data. For example, Scale AI could be a source of new human-generated data. By new, we mean the data is specifically acquired for the purposes of building the model.","We use human generated data as part of three feedback methods to improve our models:

1. Reward modeling: We train models to understand human preferences using techniques like Direct Preference Optimization (DPO) and Proximal Policy Optimization (PPO).


2. Reinforcement Learning from Human Feedback (RLHF): We collect specific human preference data to guide how models learn which outputs are most helpful and appropriate.


3. Red teaming: Our subject matter experts in various fields actively test our models, identifying potential issues and vulnerabilities.",The developer describes the function of new human-generated data but not its sources.,,0
Instructions for data generation,"For each of the top-5 sources of human-generated data, what instructions does the developer provide for data generation?","The instructions should be those provided to the data source. For example, if a third-party vendor works directly with the data laborers to produce the data, the instructions from the developer to this vendor should be disclosed.",Amazon does not disclose this information publicly. We do state publicly that we create guidelines that are used to train annotators.,The developer does not provide instructions they provide to sources of new human-generated data.,,0
Data laborer practices,"For the top-5 sources of human-generated data, how are laborers compensated, where are they located, and what labor protections are in place?","For each data source, we require (i) the compensation in either USD or the local currency, (ii) any countries where at least 25% of the laborers are located, and (iii) a description of any labor protections. We will award this point if the developer discloses that it is not aware of data laborer practices.",Amazon does not disclose this information publicly,The developer does not provide information about data laborer practices for new human-generated data.,,0
Synthetic data sources,What are the top-5 sources (by volume) of synthetic data acquired for building the model?,We define a source of synthetic data as a non-human mechanism (e.g. a machine learning model) used to generate the data.,Amazon generates synthetic data using propriety models as part of its Automated Red-Teaming efforts to improve robustness of the Nova models. ,"The developer does not describe the sources of synthetic data for model training, namely the specific models used.",,0
Synthetic data purpose,"For the top-5 sources of synthetically generated data, what is the primary purpose for data generation?",We define a source of synthetic data as a non-human mechanism (e.g. a machine learning model) used to generate the data.,"Amazon generates synthetic data using propriety models as part of its Automated Red-Teaming efforts to improve robustness of the Nova models. Using existing adversial prompts as seeds, Amazon generates additional prompts. We also automatically generate multiturn, multilingual, and multimodal attacks against our system using our Automated Red-Teaming system. ",The developer describes the purpose for synthetic data creation.,,1
Data processing methods,What are the methods the developer uses to process acquired data to determine the data directly used in building the model?,"We will award this point for disclosure of all of the methods used to process acquired data. Data processing refers to any method that substantively changes the content of the data. For example, compression or changing the data file format is generally not in the scope of this indicator.","We used AWS EMR and AWS Batch for data filtering, deduplication, and enrichment pipelines.",The developer lists three high-level data processing methods.,,1
Data processing purpose,"For each data processing method, what is its primary purpose?","Data processing refers to any method that substantively changes the content of the data. For example, compression or changing the data file format is generally not in the scope of this indicator.","We used AWS EMR and AWS Batch for data filtering, deduplication, and enrichment. An example of data filetering is de-identifying or removing certain types of personal data from our training data, when feasible. Enrichment refers to processes such as the addition or modification of metadata to training data.","The developer does not describe the purpose for specific data processing methods, but the purpose of data filtering is only partially specified in relation to personal information and the substantive purpose of enrichment is not specified.",,0
Data processing techniques,"For each data processing method, how does the developer implement the method?","Data processing refers to any method that substantively changes the content of the data. For example, compression or changing the data file format is generally not in the scope of this indicator.","We used AWS EMR and AWS Batch for data filtering, deduplication, and enrichment pipelines.",The developer does not describe the techniques that implement the data processing steps in adequate depth.,,0
Data size,Is the size of the data used in building the model disclosed?,"To receive this point, the developer should report data size in appropriate units (e.g. bytes, words, tokens, images, frames) and broken down by modality. Data size should be reported to a precision of one significant figure (e.g. 4 trillion tokens, 200 thousand images). The size should reflect data directly used in building the model (i.e. training data) and not data that was acquired but unused, or data used to evaluate the model.","We do not disclose token size for model training. However, we provide context length capabilities for each of our understanding models as follows:

Nova Pro: 300k tokens
Nova Lite: 300k tokens
Nova Micro: 128k tokens
Nova Premier: 1 million tokens ","The developer does not provide the dataset size, instead providing the context length.",,0
Data language composition,"For all text data used in building the model, what is the composition of languages?","To receive this point, the developer should report (i) all languages which make up at least 1% of the data and their corresponding proportions and (ii) a brief description of how languages are labeled (if a publicly available tool is used, include a link to the tool). Proportions should be reported to a precision of two significant figures and should describe proportions of documents labeled with some langauge. An ""Unknown"" category may be included to denote documents where the language could not be identified.","Our models were trained by curating data from over 200 languages, with particular emphasis on Arabic, Dutch, English, French, German, Hebrew, Hindi, Italian, Japanese, Korean, Portuguese, Russian, Simplified Chinese, Spanish, and Turkish.","The developer provides a high-level description of languages of emphasis, but this is insufficient precision and does not describe the method for language identification.",,0
Data domain composition,"For all the data used in building the model, what is the composition of domains covered in the data?","To receive this point, the developer should report the composition of the main domains included in the data used to train the model. This data should be at a level of granularity lower than broad claims about training on ""internet data"". For example, this could include the proportion of data from e-commerce, social media, news, code, etc. based on the URLs from which the data is sourced. Proportions should be reported to a precision of one significant figure.",We do not disclose this information publicly.,The developer does not provide information about the domain-level composition of the training data.,,0
External data access,Does a third-party have direct access to the data used to build the model?,"By a third-party, we mean entities that are financially independent of the developer.  We will award this point if at least one such entity is named as having direct access to the data. With that said, we may award this point if the developer provides justifications for prohibiting access to narrowly-scoped parts of the data. ","No, third parties do not have direct access to the data used to build the model. ","The developer does not provide access to the training data to any external entity, which is insufficient for this indicator because ""we will award this point if at least one such entity is named as having direct access to the data"".",,0
Data replicability,Is the data used to build the model described in enough detail to be externally replicable?,We will award this point if the description contains (i) a list of all publicly available training data and where to obtain it and (ii) a list of all training data obtainable from third parties and where to obtain it. These conditions refer to criteria 2 and 3 under the OSI Open Source AI v1.0 definition.,We do not disclose our training dataset list.,"The developer does not provide sufficient information to meaningfully replicate the training data, because of the use of several other types of data beyond publicly available datasets.",,0
Compute usage for final training run,Is the amount of compute used in the model's final training run disclosed?,"Compute should be reported in appropriate units, which most often will be floating point operations (FLOPs), along with a description of the measurement methodology, which may involve estimation. Compute should be reported to a precision of one significant figure (e.g. 5 x 10^25 FLOPs). This number should represent the compute used to train the final model across all model stages.",We do not disclose compute values publicly.,The developer does not provide information about training compute.,,0
Compute usage including R&D,"Is the amount of compute used to build the model, including experiments, disclosed?","Compute should be reported in appropriate units, which most often will be floating point operations (FLOPs), along with a description of the measurement methodology, which may involve estimation. Compute should be reported to a precision of one significant figure (e.g. 7 x 10^26 FLOPs). Compared to the previous indicator, this indicator should include an estimation of the total compute used across experiments used towards the final training run for the model (such as including hyperparameter optimization or other experiments), and not just the final training run itself.",Compute used to train Amazon Nova Premier is not disclosed.,The developer does not provide information about training compute.,,0
Development duration for final training run,Is the amount of time required to build the model disclosed?,"The amount of time should be specified in terms of both the continuous duration of time required and the number of hardware hours used. The continuous duration of time required to build the model should be reported in weeks, days, or hours to a precision of one significant figure (e.g. 3 weeks). The number of hardware hours should be reported to a precision of one significant figure and include the type of hardware hours. No form of decomposition into phases of building the model is required for this indicator, but it should be clear what the duration refers to (e.g. training the model, or training and subsequent evaluation and red teaming).",Amount of time to train Amazon Nova Premier is not disclosed. ,The developer does not provide information about training duration.,,0
Compute hardware for final training run,"For the primary hardware used to build the model, is the amount and type of hardware disclosed?","In most cases, this indicator will be satisfied by information regarding the number and type of GPUs or TPUs used to train the model. The number of hardware units should be reported to a precision of one significant figure (e.g. 800 NVIDIA H100 GPUs). We will not award this point if (i) the training hardware generally used by the developer is disclosed, but the specific hardware for the given model is not, or (ii) the training hardware is disclosed, but the amount of hardware is not. We will award this point even if information about the interconnects between hardware units is not disclosed.","Although the type and amount of hardware used to train Amazon Nova Premier is not specifically disclosed, Section 6 of the Amazon Nova Technical Report gives details on the hardware infrastructure used to train the Amazon Nova family of models. The Amazon Nova family of models were trained on Amazon’s custom Trainium1 (TRN1) chips, NVIDIA A100 (P4d instances), and H100 (P5 instances) accelerators.","The developer provides a list of the types of hardware units, but not the count (to the specified precision), which is insufficient for this indicator.",,0
Compute provider,Is the compute provider disclosed?,"For example, the compute provider may be the model developer in the case of a self-owned cluster, a cloud provider like Microsoft Azure, Google Cloud Platform, or Amazon Web Services, or a national supercomputer. In the event that compute is provided by multiple sources or is highly decentralized, we will award this point if a developer makes a reasonable effort to describe the distribution of hardware owners.","Based on Section 6 of the Amazon Nova Technical Report, the Amazon Nova family of models is said to be trained on AWS resources including AWS SageMaker, AWS SageMaker-managed Elastic Kubernetes Service (EKS) clusters, AWS File System X (FSx), Amazon Simple Storage Service (S3). ",The developer provides a list of the compute providers within AWS.,,1
Energy usage for final training run,Is the amount of energy expended in building the model disclosed?,"Energy usage should be reported in appropriate units, which most often will be megawatt-hours (mWh), along with a description of the measurement methodology, which may involve estimation. Energy usage should be reported to a precision of one significant figure (e.g. 500 mWh). No form of decomposition into compute phases is required, but it should be clear whether the reported energy usage is for a single model run or includes additional runs, or hyperparameter tuning, or training other models like reward models, or other steps in the model development process that necessitate energy usage. If the developer is unable to measure or estimate this quantity due to information not being available from another party (e.g. compute provider), we will award this point if the developer explicitly discloses what information it lacks and why it lacks it.",Energy required to train Amazon Nova Premier is not disclosed.,The developer does not provide information about the energy and environmental impacts of model training.,,0
Carbon emissions for final training run,Is the amount of carbon emitted in building the model disclosed?,"Emissions should be reported in appropriate units, which most often will be tons of carbon dioxide emitted (tCO2), along with a description of the measurement methodology, which may involve estimation. Emissions should be reported to a precision of one significant figure (e.g. 500 tCO2). No form of decomposition into compute phases is required, but it should be clear whether the reported emissions is for a single model run or includes additional runs, or hyperparameter tuning, or training other models like reward models, or other steps in the model development process that generate emissions. If the developer is unable to measure or estimate this quantity due to information not being available from another party (e.g. compute provider), we will award this point if the developer explicitly discloses what information it lack and why it lacks it. Emissions should correspond with the energy used in the previous indicator.",Carbon emissions from the training of Amazon Nova Premier is not disclosed.,The developer does not provide information about the energy and environmental impacts of model training.,,0
Water usage for final training run,Is the amount of clean water used in building the model disclosed?,"Clean water usage should be in appropriate units, which most often will be megaliters, along with a description of the measurement methodology, which may involve estimation. Clean water usage should be reported to a precision of one significant figure (e.g., 5000ML). No form of decomposition into compute phases is required, but it should be clear whether the reported water usage is for a single model run or includes additional runs, or hyperparameter tuning, or training other models like reward models, or other steps in the model development process that necessitates water usage. If the developer is unable to measure or estimate this quantity due to information not being available from another party (e.g. compute provider), we will award this point if the developer explicitly discloses what information it lacks and why it lacks it.",Water usage from the training of Amazon Nova Premier is not disclosed.,The developer does not provide information about the energy and environmental impacts of model training.,,0
Internal compute allocation,How is compute allocated across the teams building and working to release the model?,"To receive a point, the developer should provide the compute allocated to each team involved in training the model. We understand there might be no clear allocation of compute across different teams; in that case, report an estimate of the compute used over the last year. Compute allocation should be reported to at least one significant figure.",Internal compute allocations across teams working on the training and development of Amazon Nova family of models are not disclosed. ,The developer does not provide information about internal compute allocation.,,0
Model stages,Are all stages in the model development process disclosed?,"Stages refer to each identifiable step that constitutes a substantive change to the model during the model building process. We recognize that different developers may use different terminology for these stages, or conceptualize the stages differently. We will award this point if there is a clear and complete description of these stages.","We define four stages in building Nova Premier: (1) unsupervised pretraining using a mixture of multilingual and multimodal data from licensed, proprietary, open source, and public datasets, (2) Supervised Fine-Tuning (SFT) on instruction-demonstration pairs including multimodal ones, (3) reward model (RM) training based on human preference data, and (4) final alignment through Direct Preference Optimization (DPO) and Proximal Policy Optimization (PPO) to ensure the model follows human preferences in both quality and responsibility.",The developer lists four high-level stages for model training.,,1
Model objectives,"For all stages that are described, is there a clear description of the associated learning objectives or a clear characterization of the nature of this update to the model?","We recognize that different developers may use different terminology for these stages, or conceptualize the stages differently. We will award this point if there is a clear description of the update to the model related to each stage, whether that is the intent of the stage (e.g. making the model less harmful), a mechanistic characterization (e.g. minimizing a specific loss function), or an empirical assessment (e.g. evaluation results conducted before and after the stage).","During the pre-training stage, the objective is to optimize model for next-token prediction accuracy.
During the supervised fine-tuning stage, the objective is to optimize model correctness and helpfulness for downstream tasks (i.e. instruction following) and specific domains (i.e. coding).
During the reward model training stage, the objective is to minimize a pairwise cross-entropy loss so the reward model approximates human preference for a given input.
During the final model training stage, the objective is to align the model with human preferences in both quality and responsibility.",The developer discloses the objective associated with each training stage.,,1
Code access,Does the developer release code that allows third-parties to train and run the model?,The released code does not need to match the code used internally. ,Amazon Nova Premier on Amazon Bedrock is released with a variety of sample code and default parameters for using Amazon Nova models on Bedrock. ,"The developer does not provide code for model training, though does release other types of supplementary code.",,0
Organization chart,How are employees developing and deploying the model organized internally? ,"To receive a point, the developer should provide both the internal organization chart for the team developing the model as well as the headcounts (or a proportion of headcounts) by the team.",Amazon's organizational chart for teams supporting the development of Amazon Nova family of models is not disclosed. ,The developer does not provide information about the organization chart relevant to model training.,,0
Model cost,What is the cost of building the model?,"Monetary cost should be reported in appropriate currency (e.g. USD), along with the measurement methodology, which may involve estimation. Cost should be reported to a precision of one significant figure (e.g. 200 million USD). ",The cost of developing Amazon Nova Premier is not disclosed. ,The developer does not provide information about the cost to build their flagship model.,,0
Basic model properties,Are all basic model properties disclosed?,"Basic model properties include: the input modality, output modality, model size, model components, and model architecture. To receive a point, all model properties should be disclosed. Modalities refer to the types or formats of information that the model can accept as input. Examples of input modalities include text, image, audio, video, tables, graphs. Model components refer to distinct and identifiable parts of the model. We recognize that different developers may use different terminology for model components, or conceptualize components differently. Examples include: (i) For a text-to-image model, components could refer to a text encoder and an image encoder, which may have been trained separately. (ii) For a retrieval-augmented model, components could refer to a separate retriever module. Model size should be reported in appropriate units, which generally is the number of model parameters, broken down by named component. Model size should be reported to a precision of one significant figure (e.g. 500 billion parameters for text encoder, 20 billion parameters for image encoder). Model architecture is the overall structure and organization of a foundation model, which includes the way in which any disclosed components are integrated and how data moves through the model during training or inference. We recognize that different developers may use different terminology for model architecture, or conceptualize the architecture differently; a sufficient disclosure includes any clear, though potentially incomplete, description of the model architecture.","Input modality: Text, Image, Documents, Video 
Output modality: Text 
Model components: Multimodal foundation model with integrated safety measures and responsible AI practices. It includes components for processing text, images, and videos. 
Model architecture: Not fully disclosed, but it's described as a multimodal foundation model with a one-million token context window.
Language Support: 200+ languages with emphasis on Arabic, Dutch, English, French, German, Hebrew, Hindi, Italian, Japanese, Korean, Portuguese, Russian, Simplified Chinese, Spanish, and Turkish. 
Maximum output tokens: 10K. 
Maximum context window (tokens): 1M (equivalent to 400-page document or 90-minute video)
Configurability: Allows system prompt configuration to define persona, model instructions, and response schemas
RAG support: Supports RAG implementation through tool use and knowledge base integration.","The developer discloses the modalities, but does not fully disclose the components, architecture, and size.",,0
Deeper model properties,Is a detailed description of the model architecture disclosed?,"To receive a point, the model architecture should be described in enough detail to allow for an external entity to fully implement the model. Publicly available code or a configuration file for a model training library (e.g., GPT-NeoX) would be a sufficiently detailed description.",Not disclosed,The developer does not disclose this.,,0
Model dependencies,Is the model(s) the model is derived from disclosed?,"We will award this point for a comprehensive disclosure of the model or models on which the foundation model directly depends on or is derived from, as well as the method by which it was derived (e.g., through fine tuning, model merging, or distillation). Additionally, we will award a point if the developer discloses that the model is not dependent on or derived from any model.",Amazon Nova models are not disclosed to be derived from other models. ,The developer does not disclose this.,,0
Benchmarked inference,Is the compute and time required for model inference disclosed for a clearly-specified task on clearly-specified hardware?,The duration should be reported in seconds to a precision of one significant figure (e.g. 0.002 seconds). Compute usage for inference should be reported in FLOPs/second to a precision of one significant figure (e.g. 5 x 10^21 FLOPs/second). The hardware in this evaluation need not be the hardware the developer uses for inference. The developer can report this figure over some known or public dataset.,"It takes 0.9 seconds to receive the first token from the model after an API request is sent, i.e., TTFT(Time to First Token)=0.9 seconds.  The speed of producing subsequent output tokens after the first token is 63 tokens/second. These numbers are reported by Artificial Analysis and based on runtime Bedrock latency figures.",The developer discloses the time required for inference but does not disclose the compute.,,0
Researcher credits,Is a protocol for granting external entities API credits for the model disclosed?,"A model credit access protocol refers to the steps, requirements, and considerations involved in granting credits to external entities. We will award this point if the developer discloses key details of its protocol, including (i) where external entities can request access to credits (e.g. via an access request form); (ii) explicit criteria for selecting external entities; and (iii) its policy on granting a transparent decision on whether access has been granted within a specified, reasonable period of time. Additionally, we will award a point if the developer discloses that it does not grant external entities API credits.",Not disclosed,The developer does not disclose this.,,0
Specialized access,Does the developer disclose if it provides specialized access to the model?,"Specialized access could include several categories, such as early access, subsidized access, or deeper access (e.g., to model weights or checkpoints, that are not publicly available). We will award this point if the developer discloses (i) if it provides specialized access and (ii) statistics on the number of users granted access across academia, industry, non-profits, and governments, to one significant figure.","No, Amazon does not provide specialized access to Nova models, including Amazon Nova Premier.",The developer discloses that no specialized access is provided.,,1
Open weights,Are the model's weights openly released?,"To receive this point, model weights need to be publicly available at no cost. Developers may receive this point even if there are some restrictions on the external entities that are permitted access (e.g. geographic restrictions), insofar as these restrictions are transparent (e.g. via a license or some high-level description of who has been granted access to the foundation model).","No, Nova Premier's model weights are not openly released.",The weights are not openly released.,,0
Agent Protocols,Are the agent protocols supported for the model disclosed?,"Agent protocols are specifications that define how autonomous agents exchange messages, context, or function calls with other agents, tools, or services (e.g., Anthropic’s Model Context Protocol (MCP) and Google’s Agent‑to‑Agent (A2A) spec). To earn this point, documentation must enumerate each protocol and describe any deviations or proprietary extensions. ","Amazon Nova Pro, Lite, and Micro models can be used as agents. Amazon recently launched Strands Agents an open source SDK that takes a model-driven approach to building and running AI agents. Strands supports model integrations (including Nova) via Bedrock and works with MCP and will soon with with A2A. ",The developer discloses agent protocols that the model supports.,,1
Capabilities taxonomy,Are the specific capabilities or tasks that were optimized for during post-training disclosed?,"Capabilities refer to the specific and distinctive functions that the model can perform. We recognize that different developers may use different terminology for capabilities, or conceptualize capabilities differently. We will award this point for a list of capabilities specifically optimized for in the post-training phase of the model, even if some of the capabilities are not reflected in the final model.","We focus on the following capabilities during post-training: 
(1) Code generation 
(2) Retrieval-Augmented Generation (RAG) for retrieving information from reliable, up-to-date sources 
(3) Video understanding and interpreting content of video scenes 
(4) Document understanding 
(5) Function calling for producing outputs that elicit correct responses from application APIs 
(6) Agentic interactions for multiturn interactions on the customer's behalf",The developer discloses the capabilities optimized for during post-training.,,1
Capabilities evaluation,Does the developer evaluate the model's capabilities prior to its release and disclose them concurrent with release?,"The evaluations must contain precise quantifications of the model's behavior in relation to the capabilities specified in the capabilities taxonomy. We will award this point for any clear, but potentially incomplete, evaluation of multiple capabilities.","We evaluate the Amazon Nova models across a variety of capabilities and share the results in the Technical Report and Model Card. For Amazon Nova Premier, we share performance on public benchmarks across text, multi-modal, and angentic capabilities. Precise quanitifications are available in Section 2.1 of the Model Card

Updated: Page 3 of the Amazon Nova Premier Technical Report includes results for Nova Pro and Nova Premier on on text, multimodal, and agentic capabilities for a diverse set of capabilities across different benchmarks. https://assets.amazon.science/e5/e6/ccc5378c42dca467d1abe1628ec9/amazon-nova-premier-technical-report-and-model-card.pdf",Table 1 specifies benchmarks and results for all capabilities in the taxonomy.,,1
External reproducibility of capabilities evaluation,Are code and prompts that allow for an external reproduction of the evaluation of model capabilities disclosed?,"The released code and prompts need not be the same as what is used internally, but should allow the developer's results on all capability evaluations to be reproduced. The released code must be open source, following the OSI definition of open source.","We provide the prompt templates for all benchmarks at: https://huggingface.co/datasets/amazon-agi/Amazon-Nova-1.0-Premier-evals.

Updated: Code and prompts to reproduce evaluations can be found at : https://huggingface.co/datasets/amazon-agi/Amazon-Nova-1.0-Premier-evals","Prompts and methodology are provided in the HF link but not any code.

In addition, the HF link does not cover all of the benchmarks in Table 1. Out of the 16 evaluations specified in Table 1, MBXP, OCRBench-v2, SimpleQA, SWE-Bench Verified are missing from the provided HF link (though, for two of these benchmarks, the developer discloses that they use the official prompts).

For OCRBench-v2, the developer specifies ""We use the official prompt of the benchmark for evaluation and we report accuracy across all tasks"".

For SimpleQA, the developer specifies ""We compute
accuracy (correctness) using the prompt shared in the SimpleQA paper, and GPT-4o-2024-11-20 as a judge"".

For SWEBench Verified, the developer specifies ""Specifically, we use a simple internal agentic scaffold on a 500 instance subset of SWE-bench known as SWE-bench Verified, and we report resolved rate"".",,0
Train-test overlap,Does the developer measure and disclose the overlap between the training set and the dataset used to evaluate model capabilities?,"We will award this point if, with every capability evaluation for which the developer reports results, the developer reports the overlap between the training set of the model and the dataset used for evaluation, as well as the general methodology for computing train-test overlap (e.g. a description of how n-gram matching was used). ",Not disclosed,The developer does not disclose this.,,0
Risks taxonomy,Are the risks considered when developing the model disclosed?,"Risks refer to possible negative consequences or undesirable outcomes that can arise from the model's deployment and usage. These consequences or outcomes may arise from model limitations (functions that the model cannot perform) or issues with the model's trustworthiness (e.g., its lack of robustness, reliability, calibration). We recognize that different developers may use different terminology for risks, or conceptualize risks differently. We will award this point for a complete list of risks considered, even if some of the risks are not reflected in the final model.","Yes, the service card discusses the following risks that Nova Premier has been evaluated for:
(1) Frontier Risks: Chemical, Biological, Radiological, and Nuclear (CBRN) Weapons Proliferation, Offensive Cyber Operations, Automated AI Research and Development (AI R&D)
(2)Safety Risks: Harmlessness, CSAM
(3)Fairness
(4)Robustness
(5) Privacy",The developer discloses the list of risks considered.,,1
Risks evaluation,Does the developer evaluate the model's risks prior to its release and disclose them concurrent with release?,The evaluations must contain precise quantifications of the model's behavior in relation to the risks specified in the risk taxonomy. We will award this point for clear evaluations of the majority of the states risks.,"The Amazon Nova Premier Service Card states that, on average, Amazon Nova FMs correctly produce safe responses to over 90% of harmful prompts in a proprietary dataset (2.4K samples) designed to elicit model responses harmful content (for example, self-harm, violence, animal abuse).

Updated: (1) Frontier Risks are reported on in Nova Premier’s Frontier Model Safety Framework Risk Assessment

* CBRN: WMDP-Bio (0.84), WMDP-Chem (0.66), Protocol-QA-MCQ (0.48), BioLP-Bench (0.23)
* Offensive Cyber: Proprietary Knowledge Benchmark (~0.81), Proprietary CTF Benchmark (~0.80)
* AI R&D: On the RE-Bench tasks, Nova Premier showed foundational skills in parsing task intent, initiating complex workflows, and debugging, but it was unable to drive fully automated research, and its final solutions were judged to be either non-functional or underperforming.

(2) Safety Risks are reported on in Nova Premier’s Service Card

* Harmlessness: Amazon Nova FMs correctly product safe reponses on >90% of harmful prompts in a proprietary dataset (2.4K samples)

(3-5) Quantiative benchmarks are not reported for Fairness, Robustness, or Privacy.

https://www.amazon.science/publications/evaluating-the-critical-risks-of-amazons-nova-premier-under-the-frontier-model-safety-framework",The disclosed evaluation results do not cover a majority of risks in the taxonomy: categories 1 and 2 are covered in the taxonomy but not 3-5.,,0
External reproducibility of risks evaluation,Are code and prompts to allow for an external reproduction of the evaluation of model risks disclosed?,"The released code and prompts need not be the same as what is used internally, but should allow the developer's results on all risk evaluations to be reproduced. The released code must be open-source, following the OSI definition of open-source.",Amazon does not release code / prompts needed to externally produce risk evaluations,The developer does not disclose this.,,0
Pre-deployment risk evaluation,Are the external entities have evaluated the model pre-deployment disclosed?,"By external entities, we mean entities that are significantly or fully independent of the developer. We will award this point if the developer specifies the entity that carried out the pre-deployment analysis, discloses the terms of the analysis (such as conditions for releasing the evaluation results or the developer's control over the final results), as well as any financial transaction between the parties. We will award this point if the developer discloses no external entities have evaluated the model pre-deployment, or discloses only terms of the analysis where it is not bound by NDA while still naming all external entities.","Yes, the external entities that evaluated the model pre-deployment are explicitly disclosed in the text. Here are the pre-release external evaluators:
Red Teaming Firms:
ActiveFence
Innodata
CBRN Capabilities Assessment:
Gomes Group (for chemical synonym vulnerabilities)
Nemesys (for nuclear facility threats)
Deloitte (for biological weapons-related scientific knowledge)
Framework Evaluations:
Nemesys Insights
METR
Runtime Performance:
Artificial Analysis (described as ""an independent entity that benchmarks AI models and hosting providers"")

Updated: We contract and pay external evaluators for their services in evaluating and assessing our models. These entities include red-teaming firms (ActiveFence, Gomes Group, Innodata), Frontier Capability Assessors (Gomes Group, Nemeysis, Deloitte, METR).","The developer discloses the external entities that have evaluated the model pre-deployment. The developer also discloses the financial transactions between the parties. However, the developer does not disclose the terms of the analysis.
",,0
External risk evaluation,Are the parties contracted to evaluated model risks disclosed?,"We will award this point if the developer discloses statistics regarding all contracted parties that are responsible for evaluating risks (not limited to external entities or pre-deployment evaluation). This includes the number of contracted for-profit or non-profit entities, government entities, independent contractors, and researchers contracted by the developer to evaluate risks. We will award this point if the developer discloses it has no such contracts.","Yes, the external entities that evaluated the model pre-deployment are explicitly disclosed in the text. Here are the pre-release external evaluators:
Red Teaming Firms:
ActiveFence
Innodata
CBRN Capabilities Assessment:
Gomes Group (for chemical synonym vulnerabilities)
Nemesys (for nuclear facility threats)
Deloitte (for biological weapons-related scientific knowledge)
Framework Evaluations:
Nemesys Insights
METR
Runtime Performance:
Artificial Analysis (described as ""an independent entity that benchmarks AI models and hosting providers"")","The developer provides a list of entities which evaluate the model pre-deployment. The developer does not explicitly specify that this list of entities consitutes all of the contracted entities, but it can be reasonably interpreted as such, so we choose to award a point here. We recommend that the developer clarify whether this is the case.",,1
Mitigations taxonomy,Are the post-training mitigations implemented when developing the model disclosed?,"By post-training mitigations, we refer to interventions implemented by the developer during the post-training phase to reduce the likelihood and/or the severity of the model’s risks. We recognize that different developers may use different terminology for mitigations, or conceptualize mitigations differently. We will award this point for a complete list of mitigations considered, even if some of the mitigations are not reflected in the final model. Alternatively, we will award this point if the developer reports that it does not mitigate risk in this way.","We implement the following post-training mitigations to address model risks:
1. Supervised Fine Tuning (SFT) and Learning with Human Feedback (LHF) for model alignment across responsible AI dimensions
2. Runtime input and output moderation systems:
- Input moderation to detect and block/modify prompts containing malicious, insecure, illegal material, or alignment bypass attempts
- Output moderation to ensure content adheres to Responsible AI objectives
3. Training data safeguards including:
- Data review process across training stages
- De-identification and removal of certain types of personal data
4. Fine-tuning safeguards to make models resilient against malicious customer fine-tuning that could undermine initial Responsible AI alignment
5. For RLHF training specifically:
- Use of a responsible-AI-specific reward model
- Training on internally annotated data across all responsible-AI dimensions
6. Watermarking for image and video generation outputs with C2PA metadata
7. Robust model alignment against adversarial inputs, focusing on preventing:
- Sensitive data exfiltration
- Unauthorized action execution
- Service availability degradation
- Malicious content generation",The developer discloses the post-training mitigations implemented.,,1
Mitigations taxonomy mapped to risk taxonomy,Does the developer disclose how the post-training mitigations map onto the taxonomy of risks?,"We will award this point for a complete mapping of the primary risk that each mitigation is meant to address, even if the mitigation potentially maps on to other risks in the taxonomy. Alternatively, we will award this point if the developer reports that it does not mitigate risk.","We use supervised fine tuning (SFT) and reinforcement learning with human feedback (RLHF) to address: (1) Safety, fairness, controllability, veracity and robustness, and privacy and security dimensions and (2) RLHF specifically uses a responsible-AI-specific reward model trained on internally annotated data.

We use runtime input and output moderation systems to prevent: (1) Malware, malicious content, and cyber-crime facilitation; (2) Misinformation that undermines public institutions or endangers health; (3) Disrespect, discrimination, or stereotyping towards groups; (4) Inappropriate content including insults, profanity, obscenity; (5) Bias against demographic groups; and (6) Prompt injection and jailbreaking attempts.",The post-training mitigations are clearly mapped onto the model risks.,,1
Mitigations efficacy,Does the developer evaluate and disclose the impact of post-training mitigations?,"We will award this point if the developer discloses the results on the risk evaluations before and after the post-training mitigations are applied. Alternatively, we will award this point if the developer reports that it does not mitigate risk in this way.",Not disclosed,The developer does not disclose this information.,,0
External reproducibility of mitigations evaluation,Are code and prompts to allow for an external reproduction of the evaluation of post-training mitigations disclosed?,"The released code and prompts need not be the same as what is used internally, but should allow the developer's results on all mitigations evaluations to be reproduced. The released code must be open-source, following the OSI definition of open-source. Alternatively, we will award this point if the developer reports that it does not mitigate risk.",Not disclosed,The developer does not disclose this information.,,0
Model theft prevention measures,Does the developer disclose the security measures used to prevent unauthorized copying (“theft”) or unauthorized public release of the model weights?,"This indicator assesses the developer's disclosures regarding how it addresses the risk that malicious actors or insiders could exfiltrate or replicate proprietary weights. Security measures could include insider threat analysis and detection, in addition to external threat management. Examples of such measures include encryption at rest, key management, remote attestation, or auditing for suspicious queries. We will award a point if the developer discloses specific steps taken to safeguard the model weights or that none are implemented.",The appendix of Amazon Frontier Model Safety Framework discloses details on security measures used to protect senstiive assets and data across Amazon,The developer discloses the security measures used to prevent model theft.,,1
Release stages,Are the stages of the model's release disclosed?,"Release stages include A/B testing, release on a user-facing product, GA release, open-weight release, etc.  We recognize that the release of a foundation model falls along a spectrum, with many forms of partial release, and that different developers may conceptualize release differently. We will award a point if the developer provides a clear identification of the stages through which the model was released.","No disclosure. 
Updated: For the launch of Nova Premier, we launched a Private Beta to internal and external customers for approximately 4-5 weeks before releasing a publicly available GA candidate. Between Private Beta and GA release, we conducted both quantiative and qualitative evaluations to mitigate risks in the GA candidate released to customers. Beta testing is for evaluation purposes prior to GA launch. Private Betas are not released to testers' end users",The developer discloses the stages of release for Nova Premier.,,1
Risk thresholds,Are risk thresholds disclosed?,"Risk thresholds determine when a risk level is unacceptably high to a developer (e.g. leading to the decision to not release a model), moderately high (e.g. triggering additional safety screening), or low enough to permit normal usage.

We will award this point if the developer discloses explicit risk thresholds that clarify (i) which harmful outcomes are being scored, (ii) how the scores are computed (in general terms, not necessarily disclosing internal algorithms), and (iii) what triggers an action to block, delay, or otherwise modify a model's release. 

Alternatively, we will award a point if the developer discloses that it does not consider explicit risk thresholds during model release. ","Amazon's Frontier Model Safety Framework outlines risk thresholds across three domains which frontier models within Amazon are evaluated for prior to deployment:
a) Chemical, Biological, Radiological, and Nuclear (CBRN) Weapons Proliferation b) Offensive Cyber Operations c) Automated AI Research and Development (AI R&D)

For each domain, a general description of the threshold is provided:
CBRN: ""AI at this level will be capable of providing expert-level, interactive instruction that provides material uplift (beyond other publicly available research or tools) that would enable a non-subject matter expert to reliably produce and deploy a CBRN weapon.""

Offensive Cyber Operations: ""AI at this level will be capable of providing material uplift (beyond other publicly available research or tools) that would enable a moderately skilled actor (e.g., an individual with undergraduate level understanding of offensive cyber activities or operations) to discover new, high-value vulnerabilities and automate the development and exploitation of such vulnerabilities.""

Automated AI R&D: ""AI at this level will be capable of replacing human researchers and fully automating the research, development, and deployment of frontier models that will pose severe risk such as accelerating the development of enhanced CBRN weapons and offensive cybersecurity methods.""

Further, Amazon makes a commitment to  not deploy frontier AI models that exceed specified risk thresholds without appropriate safeguards in place.",The developer discloses risk thresholds.,,1
Versioning protocol,Is there a disclosed protocol for versioning and deprecation of the model?,"We will award a point if the developer discloses how model versions are labeled, updated, deprecated, and communicated to users.","Amazon does not publicly disclose versioning protocols for Amazon Nova family of models, however, Amazon Bedrock assigns each model available on Amazon Bedrock a model lifecycle stage.","The developer discloses information about their deprecation protocol, but does not disclose information about versioning.",,0
Change log,Is there a disclosed change log for the model?,"We will award a point if the developer publishes a version-by-version record of new features, fixes, or performance improvements.","Amazon Nova Reel is on its 1.1 version; updates have been published in the accompanying announcement blog.

New versions of other Amazon Nova models have not yet been released. 

FMTI Team - https://docs.aws.amazon.com/nova/latest/userguide/doc-history.html ","The disclosure provided by the developer lists details only for a single update/release, which is not sufficient for a point. However, the documentation releases in their ""User Guide for Amazon Nova"" does list new features/performance improvements, which we deem to be a sufficient change log.",,1
Foundation model roadmap,"Is a forward-looking roadmap for upcoming models, features, or products disclosed?","A foundation model roadmap is a transparent statement about how the developer intends to evolve or expand its LLM offerings, including upcoming models, major feature releases, or expanded products based on the model, along with approximate timelines or version milestones. It can be high-level (e.g., “new model Q2 2025”), but must exist publicly.","At re:Invent 2024, Amazon pre-announced launches of a speech-to-speech model (launched as Amazon Nova Sonic in April 2025), Amazon Nova Premier (launched April 2025) and an any-to-any modality model coming in 2025.","In the past, the developer has publicly disclosed the launch of new models.",,1
Top distribution channels,Are the top-5 distribution channels for the model disclosed?,"We define distribution channels to be either an API provider (a pathway by which users can query the model with inputs and receive outputs) or a model distributor (a pathway by which model weights are released). We recognize that distribution channels may arise without the knowledge of the model developer. For example, the weights of a model may be released through one distribution channel and then be distributed through other channels.

Distribution channels can be ranked by any reasonable metric (e.g., number of queries, number of downloads, number of users, revenue). A description of the metric should be provided.

API providers and model distributors may be ranked separately using different metrics as long as the total number of distribution channels equals five (if five distribution channels exist). For example, the developer may choose to disclose the top-3 API providers (ranked by the number of queries) and the top-2 model distributors (ranked by the number of downloads).",Amazon provides access to the Amazon Nova models through Amazon Bedrock and through amazon.nova.com. No additional distribution channels are disclosed and Amazon does not publicy share ranking of these two distribution channels. ,The developer discloses two distribution channels and specifies that these are the only two.,,1
Quantization,Is the quantization of the model served to customers in the top-5 distribution channels disclosed?,We will award this point for a disclosure of the model precision in each of the top-5 distribution channels. ,Amazon does not disclose specific details regarding the quantization of its Amazon Nova models that are served to customers. ,The developer does not disclose this information.,,0
Terms of use,Are the terms of use of the model disclosed?,"We define terms of use to include terms of service and model licenses. We will award this point for a pointer to the terms of service or model license.

In the event that model's licenses are written more generally, it should be clear which assets they apply to. We recognize that different developers may adopt different business models and therefore have different types of model licenses. Examples of model licenses include responsible AI licenses, open-source licenses, and licenses that allow for commercial use.

Terms of service should be disclosed for each of the top-5 distribution channels. However, we will award this point if there are terms-of-service that appear to apply to the bulk of the model’s distribution channels.",Amazon Nova models are governed by nova.amazon.com Terms of Use and AWS Terms of Service ,The developer provides terms of service that appear to apply to the bulk of the distribution channels.,,1
Distribution channels with usage data,What are the top-5 distribution channels for which the developer has usage data?,"We define distribution channels to be either an API provider (a pathway by which users can query the model with inputs and receive outputs) or a model distributor (a pathway by which model weights are released). We recognize that distribution channels may arise without the knowledge of the model developer. For example, the weights of a model may be released through one distribution channel and then be distributed through other channels. 

Distribution channels can be ranked by any reasonable metric (e.g., number of queries, number of downloads, number of users, revenue). A description of the metric should be provided.


We define usage data as any form of developer-exclusive data collected from any of a developer's distribution channel. A developer has access to usage data from a distribution channel if it is able to use that data for downstream purposes (e.g., analytics, training etc.). Usage data may be shared outside of the developer, but it is initially collected by the distribution channel and shared to the developer.",Amazon Nova Premier is available to customers via Amazon Bedrock and nova.amazon.com. Usage data is not available to Nova developers from usage on Amazon Bedrock. Usage data is available to Nova developers from usage on nova.amazon.com. The nova.amazon.com Terms of Use make customers aware of how usage data from engagements with Nova Premier on nova.amazon.com can be used: https://www.amazon.com/gp/help/customer/display.html?&nodeId=Tsn7s47ytlgjRBHozK,Clear that Amazon has usage data for these distribution channels,,1
Amount of usage,"For each of the top-5 distribution channels, how much usage is there?","Usage should be reported as the number of queries over the span of a month, reported to the precision of one significant figure (e.g., 50 million queries).",Amazon does not publicly disclose usage statistics for the Amazon Nova models.,Company acknowledges no disclosure,,0
Classification of usage data,"Is a representative, anonymized dataset classifying queries into usage categories disclosed?","Developers may either share a fully public dataset or a partially restricted dataset (e.g., under a research license). We will award this point if there is a clear, aggregated or sample dataset that reveals categories of tasks/queries.",Amazon does not publicly disclose any representative or anonymized datasets that classify Amazon Nova model queries into usage categories.,Company acknowledges no disclosure,,0
Data retention and deletion policy,Is a policy for data retention and deletion disclosed?,"A data retention and deletion policy is a policy for removing particular data from the training set and/or preventing it from being used if there is a user or external request (e.g., “right to be forgotten”) that also covers internal data governance. This includes whether there is a formal process to delete or retract data from future training runs and how long raw data is retained. It also clarifies how quickly deletions propagate to the model (e.g., “only in subsequent major model releases”).","Our data privacy and data security policies can be found in the AWS Data Privacy FAQ and nova.amazon.com Privacy notice

Amazon has published a privacy notice specifically addressing Privacy questions related to training of Amazon models (https://aws.amazon.com/bedrock/amazon-models/privacy/).",It remains unclear how user data is removed from Amazon models once a user requests deletion or limited processing.,,0
Geographic statistics,"Across all forms of downstream use, are statistics of model usage across geographies disclosed?","We will award this point if there is a meaningful, though potentially incomplete or vague, disclosure of geographic usage statistics at the country-level.",Amazon does not disclose statistics of model usage across geographies.,Company acknowledges no disclosure,,0
Internal products and services,What are the top-5 internal products or services using the model?,"An internal product or service is a product or service built by the developer. Products or services can be ranked by any reasonable metric (e.g., number of users, queries, revenue). A description of the metric should be provided.","Amazon does not disclose usage of Amazon Nova models by internal services, however, it has publicly stated that Alexa+ is powered by LLMs from Amazon Bedrock including Amazon Nova models",Company acknowledges no disclosure,,0
External products and services,What are the top-5 external products or services using the model?,"An external product or service is a product or service built by a party external to the developer. Products or services can be ranked by any reasonable metric (e.g., number of users, queries, revenue). A description of the metric should be provided.

We will award a point if the developer discloses that that it does not have access to such metrics about external products or services.",Reference customers for Amazon Nova models can be found on our website.,Amazon does not state whether these reference customers are owners/operators of the top 5 external products and services,,0
Users of internal products and services,How many monthly active users are there for each of the top-5 internal products or services using the model?,"An internal product or service is a product or service built by the developer. The number of users refers to users who engaged or interacted with the model through the internal product or service over the last month or averaged over the last X months (this should be specified). Number of users should be specified to one significant figure (e.g. 100,000).",Amazon does not disclose the number of active users for internal products or services using the Amazon Nova models.,Company acknowledges no disclosure,,0
Consumer/enterprise usage,"Across all distribution channels for which the developer has usage data, what portion of usage is consumer versus enterprise?","Consumer usage refers to usage by individual consumers. Enterprise usage refers to usage by enterprise customers (including government use). Consumer and enterprise usage should be calculated in terms of the number of queries by or the amount of revenue from consumer or enterprise users. Percentages should be specified to two significant digits (e.g., 12% consumer, 88% enterprise).",Amazon does not disclose portions of usage from consumer versus enterprises for Amazon Nova models.,Company acknowledges no disclosure,,0
Enterprise users,"Across all distribution channels for which the developer has usage data, what are the top-5 enterprises that use the model?",Enterprises should be ranked by the number of queries made or the amount of revenue from usage since the model's release. We will also award this point if the developer indicates it does not have access to enterprise usage data.,Amazon does not disclose the top customers for the Amazon Nova models.,Company acknowledges no disclosure,,0
Government use,What are the 5 largest government contracts for use of the model?,"This includes known government contracts of enterprise or government-specific products and services that use the model. We will award this point if the developer discloses its top five government contracts ranked monetary value, though the developer may omit contracts where it is under NDA regarding the existence of the contract.",Amazon does not disclose customers for the Amazon Nova models beyond those that are identified on our website.,Company acknowledges no disclosure,,0
Benefits Assessment,Is an assessment of the benefits of deploying the model disclosed?,We will award this point for any quantitative assessment of the benefits or potential benefits of deploying the model.,"Amazon claims that Amazon Nova Micro, Amazon Nova Lite, and Amazon Nova Pro are at least 75 percent less expensive than the best performing models in their respective intelligence classes in Amazon Bedrock.

Nova Premier can be used as a teacher model for distillation, which means you can transfer its advanced capabilities for a specific use case into smaller, faster, and more efficient models like Nova Pro, Micro, and Lite for production deployments. This enables customers to improve price and performance on their use cases. In this blog (https://aws.amazon.com/blogs/aws/amazon-nova-premier-our-most-capable-model-for-complex-tasks-and-teacher-for-model-distillation/), a distilled Nova Pro had a 20% higher accuracy for API invocations compared to the base model and consistently matched the performance of the teacher, with the speed and cost benefits of Nova Pro.
","Needs to be a real-world assessment of benefits, not just based on features of the model",,0
AI bug bounty,Does the developer operate a public bug bounty or vulnerability reward program under which the model is in scope? ,"We will award this point for a publicly documented bug bounty or vulnerability reward program describing (i) in-scope vulnerabilities (e.g., prompt bypasses, data leaks), (ii) out-of-scope items, (iii) submission process, and (iv) reward tiers or recognition if applicable. We will award a point if the developer discloses it has no AI bug bounty that encourages external researchers to report security, privacy, or adversarial vulnerabilities in the model.","Amazon runs a Vulnerability Research Program (VRP) on HackeOne platform at https://hackerone.com/amazonvrp/policy_scopes. External researchers can use this channel, with the asset being 'GenAI Apps under *.amazon.*' to responsibly disclose urgent security vulnerabilities in GenAI foundation models and applications hosted on Bedrock or nova.amazon.com. ","Amazon has a public bug bounty, states its model(s) are in scope, and the bug bounty says what is out of scope and has tiers",,1
Responsible disclosure policy,Does the developer clearly define a process by which external parties can disclose model vulnerabilities or flaws? ,"We will award this point for a description of the process external parties can use for responsbly disclosing model vulnerabilities and flaws, which should include (i) what mechanism external parties can use to disclose vulnerabilities or flaws (e.g., a form, an email) and (ii) what process follows a disclosure (e.g., how much time must parties wait until public release). This is often included with a bug bounty, but can also be standalone. We will award a point if the developer discloses it has no responsible disclosure policy.","Amazon runs a Vulnerability Research Program (VRP) on HackeOne platform at https://hackerone.com/amazonvrp/policy_scopes. External researchers can use this channel, with the asset being 'GenAI Apps under *.amazon.*' to responsibly disclose urgent security vulnerabilities in GenAI foundation models and applications hosted on Bedrock or nova.amazon.com. ","Amazon has a public bug bounty where submission can be made. No disclosures can be made to third parties, per the bug bounty's RDP: ""Thank you for joining us in supporting ethical and responsible disclosure. By participating in this program, you agree not to share publicly or privately any details or descriptions of your findings with any third party.""",,1
Safe harbor,Does the developer disclose its policy for legal action against external evaluators conducting good-faith research? ,"We will award this point if the developer discloses whether it has a policy committing it to not pursue legal action against external evaluators conducting good-faith research. This should not be only for software security vulnerabilities, but also AI flaws, and it should be based on researcher conduct standards, not at the sole discretion of the company. We will award this point if the developer provides a clear description of its policy regarding such protections for external researchers, or lack thereof. ",Amazon's policy regarding potential legal action against external evaluators conducting good-faith research remains undisclosed.,Company acknowledges no disclosure,,0
Security incident reporting protocol,Are major security incidents involving the model disclosed? ,"A security incident reporting protocol provides post-deployment transparency about serious incidents or breaches. Security incidents refer to incidents where external security threats affect the model (e.g., data breaches or DDoS attacks on the service). We will award this point if the developer states (i) how to submit a security incident report, (ii) how quickly it will respond, and (iii) when and whether results are disclosed.

Every incident need not be reported publicly, but the developer must disclose a policy determining how incidents are reported and disclosed.","We investigate all reported security vulnerabilities affecting Amazon and AWS services, software, and products including GenAI models. The security bulletin can be found here: https://aws.amazon.com/security/security-bulletins/ We would also issue a CVE and GHSA if it the issue meets the criteria of the Amazon CVE Numbering Authority (CNA) to issue those advisories","The bottom of the security bulletin page has a link for reporting a vulnerability, and the description and page state how they would report what was found",,1
Misuse incident reporting protocol,Are misuse incidents involving the model disclosed? ,"A misuse incident reporting protocol provides post-deployment transparency about incidents of misuse involving the model. As opposed to the previous indicator, this indicator is about actors misusing the model to cause real-world harm, such as misinformation operations or cybersecurity attacks. We will award this point if the developer states (i) how to submit a misuse incident report, (ii) how quickly it will respond, and (iii) when and whether results are disclosed.

Every incident need not be reported publicly, but there needs to be a policy governing how incidents are reported.","Amazon does not disclose a misuse incident reporting protocol, however, within its AUP provides a form for users to report suspected abusive activity. ",Company acknowledges no disclosure,,0
Post-deployment coordination with government,Does the developer coordinate evaluation with government bodies?,"We will award this point if the developer specifies which government bodies it is coordinating with and for what types of post-deployment evaluations. Government bodies include AI Safety Institutes, national security agencies, national labs, and international governmental enties such as UN agencies or the G7. Evaluation here may also include sharing of the developer's proprietary evaluation results for help with interpretation. ",We do not coordinate evaluations with any government entities or AI Safety Institutes. ,Company discloses no such coordination,,1
Feedback mechanisms,"Does the developer disclose a way to submit user feedback? If so, is a summary of major categories of feedback disclosed?","We will award this point if the developer (i) discloses how users can submit feedback (e.g., via a form or a thumbs up/thumbs down for model responses) and (ii) discloses aggregated or categorized feedback data (e.g. a categorization of thumbs up and thumbs down data). ","(1) For Amazon Nova models access through Amazon Bedrock, users can submit feedback through through the feedback form in the AWS AI Service Card for Nova Premier or via the feedback feature in Amazon Bedrock console. 
(2) For Amazon Nova models accessed through nova.amazon.com, users can submit feedback through the thumbs up/down buttons on responses in interactions on nova.amazon.com","Amazon discloses feedback mechanisms across distribution channels, no summary disclosed",,0
"Permitted, restricted, and prohibited model behaviors","Are model behaviors that are permitted, restricted, and prohibited disclosed?","We refer to a policy that includes this information as a model behavior policy, or a developer's policy on what the foundation model can and cannot do (e.g. such a policy may prohibit a model from responding to NSFW content). We recognize that different developers may adopt different business models and that some business models may make enforcement of a model behavior policy more or less feasible. We will award this point if at least two of the three categories (i.e. permitted, restricted, and prohibited model behaviors) are disclosed. Alternatively, we will award this point if the developer reports that it does not impose any restrictions on its model's behavior in this way.","Prohibited behaviors::
Dangerous activities, self-harm, or use of dangerous substances
Use, misuse, or trade of controlled substances, tobacco, or alcohol
Physical violence or gore
Child abuse or child sexual exploitation
Animal abuse or trafficking
Misinformation that could undermine public institutions or endanger health
Malware or content facilitating cybercrime
Discrimination or stereotyping
Insults, profanity, obscenity, pornography, hate symbols
Full nudity outside of scientific/educational contexts
Bias based on demographic characteristics

Restricted behaviors: While not explicitly labeled as ""restricted,"" the text implies caution in certain areas:
Generating content that could be construed as requesting private information
Producing outputs that will be directly surfaced to end users without review
Use in workflows producing consequential decisions without human oversight

From AWS RAI Policy:
Prohibitions. You may not use, or facilitate or allow others to use, the AI/ML Services:
for intentional disinformation or deception; 
to violate the privacy rights of others, including unlawful tracking, monitoring, and identification; 
to depict a person’s voice or likeness without their consent or other appropriate rights, including unauthorized impersonation and non-consensual sexual imagery; 
for harm or abuse of a minor, including grooming and child sexual exploitation;
to harass, harm, or encourage the harm of individuals or specific groups; 
to intentionally circumvent safety filters and functionality or prompt models to act in a manner that violates our Policies;
to perform a lethal function in a weapon without human authorization or control.",Amazon provides a helpful breakdown of prohibited and restricted behaviors.,,1
Model response characteristics,Are desired model response characteristics disclosed?,"Model response characteristics include default behaviors or behaviors that the developer steers the model to take. These may include being helpful, taking an objective point of view, or using tools only when necessary. We will award points for a clear description of desired model response characteristics or a statement that there are no such characteristics.","We configure Nova Premier's responses to:
- Provide concise answers to simple questions when information is directly available
- Include more details for yes/no questions
- Use logical reasoning for multi-hop reasoning questions
- Be transparent about information gaps by stating when exact answers cannot be found
- Include citations to support responses using markers like %[1]%, %[2]%, %[3]%
- Avoid completing prompts that could request private information
- Adhere to responsible AI objectives through runtime moderation
- Maintain user privacy by not storing or sharing customer prompts and completions
- Generate responses that align with Amazon's responsible AI dimensions including safety, fairness, controllability, veracity and robustness",Amazon provides a list of how Nova Premier's responses are configured,,1
System prompt,Is the default system prompt for at least one distribution channel disclosed?,A system prompt is defined as the prompt provided to the system by default that guides the system's behavior. We will award this point for the disclosure of the verbatim text of the full system prompt as well as an explanation for the context in which the system prompt is used.,"No, the system prompt for Amazon Nova Premier is not disclosed for the model accessed through Amazon Bedrock or through nova.amazon.com",Company acknowledges no disclosure,,0
Intermediate tokens,Are intermediate tokens used to generate model outputs available to end users? ,"Intermediate tokens are defined as any tokens generated by the model before the final output is shown to the user, such as model chains of thought. We will also award this point if a summary of intermediate tokens is made available to end users. If intermediate tokens or summaries are not made available, the developer should provide a justification.","Nova Premier makes its intermediate tokens (chain-of-thought reasoning) available to users when instructions are given, and users are advised to use specific instructions to keep the thinking brief and contain it within <thinking> tags.

This is summarized from Amazon Nova's User Guide ",Amazon discloses COT available with prompting,,1
Internal product and service mitigations,"For internal products or services using the model, are downstream mitigations against adversarial attacks disclosed?","An internal product or service is a product or service built by the developer. Adversarial attacks include prompt injection, jailbreaking, or malicious queries. Mitigations against adversarial attacks might include specialized prompt filtering, content scanning, or real-time monitoring of queries or accounts. We will award this point if the developer discloses a clear statement of methods used (e.g., a specialized prompt sanitizer or adversarial pattern detector), or if the developer states it does not implement such product-level mitigations against adversarial attacks.","To help prevent potential misuse, Amazon Bedrock implements automated abuse detection mechanisms. These mechanisms are fully automated, so there is no human review of, or access to, user inputs or model completions. To learn more, see Amazon Bedrock Abuse Detection in the Amazon Bedrock User Guide.",Amazon automatically scans user inputs,,1
External developer mitigations,Does the developer provide built-in or recommended mitigations against adversarial attacks for downstream developers?,"Downstream developers are developers who access the model through a distribution channel. Adversarial attacks include prompt injection, jailbreaking, or malicious queries. Mitigations against adversarial attacks that developers might build in or recommend include content filtering endpoints and recommended prompt templates. We will award this point if the developer discloses (i) technical mitigations (e.g., a developer provided moderation API or classifier) it offers or implements, (ii) recommended best practices or libraries for downstream developers, or (iii) an explicit statement that it does not build or recommend any particular downstream mitigations in this way.. ","Amazon Nova's User Guide  provides insights into downstream security controls and also provides recommendations to implement model content guardrails via System Prompt field. The developer also has an option to use AWS Bedrock Guardrails at the application layer to mitigate prompt injection attacks, and block harmful content or leakage of sensitive information. ",AWS Bedrock Guardrails suffices,,1
Enterprise mitigations,Does the developer disclose additional or specialized mitigations for enterprise users?,"Enterprise users are, for example, large organizations with dedicated service agreements or users of enterprise-specific API deployments or products and services. Additional or specialized mitigations may address enterprise needs such as data privacy controls, advanced prompt/response monitoring, or compliance checks with regulations such as GDPR or HIPAA. Additional or specialized mitigations may include single-tenant deployments, custom filters for specific regulated industries, or advanced logging for compliance. We will award a point if the developer at least describes these mitigations or states that it does not provide such additional or specialized enterprise mitigations.","For enterprise users using Nova via Amazon Bedrock, Bedrock's Abuse Detection mitigates potential misuse to uphold Responsible AI. ",Description of mitigations is sufficient,,1
Detection of machine-generated content,Are mechanisms that are used for detecting content generated by this model disclosed?,"A mechanism for detecting machine-generated content might include storing a copy of all outputs generated by the model to compare against, implementing a watermark on model outputs, adding cryptographic metadata (such as C2PA), or training a detector post-hoc to identify such content. We will award this point if any such mechanism is disclosed or if the developer reports that it does not have or use any such mechanism.","Amazon Nova Premier exclusively generates text outputs, which do not carry any watermkaring.

Amazon Nova Reel (video generation) and Amazon Nova Canvas (image generation) models support watermark injection (Canvas, Reel) and C2PA (Canvas).",Amazon discloses no watermark for text outputs and different watermarks for video and image models,,1
Documentation for responsible use,Does the developer provide documentation for responsible use by downstream developers?,"To receive a point, the developer should provide documentation for responsible use. This might include details on how to adjust API settings to promote responsible use, descriptions of how to implement mitigations, or guidelines for responsible use. We will also award this point if the developer states that it does not provide any such documentation. For example, the developer might state that the model is offered as is and downstream developers are accountable for using the model responsibly.","For use of Amazon Nova Premier on Amazon Bedrock, Amazon provides documentation for responsible use by developers including AI Service cards, a suite of tools for building tools responsibly such as Amazon Guardrails, SageMaker Clarify, and ML Governance, and the AWS Responsible AI Policy.

For use of Amazon Nova Premier on nova.amazon.com, Amazon provides an Acceptable Use Policy and Terms of Use.",AWS Responsible AI Policy suffices,,1
Permitted and prohibited users,Is a description of who can and cannot use the model on the top-5 distribution channels disclosed?,We will award this point for a description of the company's policies for permitted and prohibitted users on its top-5 distribution channels. We will award this point if the developer has a more general acceptable use policy that it confirms applies across these distribution channels. We will award this point if there are no restrictions on users.,"For usage of Amazon Nova models on AWS, no explicit permitted/prohibited users are described.

For usage of Amazon Nova models on nova.amazon.com, usage requirements are stated in Section 1.3 of the Terms of Use. Permitted users must be 18 years old. ",Clear description of permitted/prohibited users,,1
"Permitted, restricted, and prohibited uses","Which uses are explicitly allowed, conditionally permitted, or strictly disallowed under the acceptable use policy for the top-5 distribution channels?","We will award this point for a rough characterization of two or more of permitted, restricted, and prohibited uses across the top-5 distribution channels. We will award this point if the developer has a more general acceptable use policy that it confirms applies across these distribution channels. We will award this point if there are no restrictions on users.","For Amazon Nova models on Bedrock, prohibited uses are documented in the AWS Acceptable Use Policy and AWS Responsible AI Policy.

For Amazon Nova models on nova.amazon.com, there is a separate Acceptable Use Policy",Clear disclosure of the AUPs,,1
AUP enforcement process,What are the methods used by the developer to enforce the acceptable policy?,"We will award this point if the developer discloses the processes (automated or manual) it uses to detect, review, and respond to potential acceptable use policy violations. We will award this point for a reasonable best-effort attempt to provide the bulk of this information, though one line indicating the developer reserves the right to terminate accounts is insufficient. Alternatively, we will award this point if the developer reports that it does not use such methods to enforce its acceptable use policy.",The Amazon Nova family of models leverages Bedrock Abuse Detection service (including CSAM detection) to prevent potential misuse by users on Amazon Bedrock and amazon.nova.com,Some description of Bedrock Abuse Detection,,1
AUP enforcement frequency,Are statistics on the developer's AUP enforcement disclosed?,"We will award this point if the developer discloses enforcement statistics (e.g., violation counts or actions taken) from its enforcement of its acceptable use policy. Alternatively, we will award this point if the developer reports that it does not enforce its acceptable use policy.",Amazon does not publish statistics on Acceptable Use Policies for Amazon Bedrock or nova.amazon.com.,Company acknowledges no disclosure,,0
Regional policy variations,Are differences in the developer's acceptable use or model behavior policy across geographic regions disclosed?,"We will award this point if the developer discloses distinctions in its AUP or MBP and provides examples of differences in multiple specific regions, or states that no differences exist. For example, some jurisdictions impose content restrictions beyond those in the developer’s global policy that may necessesitate local deviations.","For use of Amazon Nova models on Bedrock, usage is governed by AWS Customer Agreement and the AWS service Terms. In the AWS Customer Agreement, differences in jurisdictions are mentioned (Section 3, Section 11).

For use of Amazon Nova models on nova.amazon.com, the Terms of Use mention restriction of usage to the US (Section 2.4)",Variations in policy by region are pointed to,,1
Oversight mechanism,Does the developer have an internal or external body that reviews core issues regarding the model prior to deployment?,"We will award this point if the developer discloses that is has such an internal or external body and provides some description of its scope, or alternatively if the developer discloses that it has no such body. An oversight mechanism covers governance structure beyond mere external risk evaluation, asking whether a formal body regularly reviews design and deployment decisions. Core issues may include model objectives, data usage, or risk mitigation.","In Amazon's Frontier Model Safety Framework, it commits to incorporate of the Safety Framework into the Amazon-wide Responsible AI Governance Program.",The developer provides a description of its oversight mechanism in its Frontier Model Safety Framework,,1
Whistleblower protection,Does the developer disclose a whistleblower protection policy?,"We will award this point if the developer discloses (i) the existence of a whistleblower protection policy, (ii) what protections are afforded to whistleblowers, (iii) how reports are handled and investigated, and (iv) any external oversight of the whistleblower protection process. This might include protections for whistleblowers who report safety, ethical, or legal concerns related to the model. We will also award this point if the developer discloses that it has no such policy.",Amazon does not have public disclosures about its whistlwblower protection policy. ,Company acknowledges no disclosure,,0
Government commitments,What commitments has the developer made to government bodies?,We will award this point if the company provides an exhaustive list of commitments it has made to government bodies in the jurisdictions where it offers its model.,"Amazon has publicly committed to collaboration as part of the G7 AI Hiroshima Process Code of Conduct, and the AI Safety Summits in the U.S. and Seoul","The developer discloses a number of government commitments it has made, though the list is incomplete as it has also signed onto the White House Voluntary Commitments.",,0
